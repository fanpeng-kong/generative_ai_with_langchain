{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 3: Getting Started with LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from config import set_environment\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring API model integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Cloud Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "PROJECT_ID = \"elevated-epoch-417712\"\n",
    "REGION = \"us-central1\"\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What NFL team won the Super Bowl in the year Justin Beiber was born?\n",
      "Answer: Let's think step by step.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Justin Bieber was born on March 1, 1994. The Super Bowl is held in February, so the Super Bowl that happened in the year Justin Bieber was born would have been Super Bowl XXVIII, which was held on January 30, 1994. The Dallas Cowboys won Super Bowl XXVIII.\\n\\nThe final answer is Dallas Cowboys'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import VertexAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = VertexAI()\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an application for customer service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardiffnlp/twitter-roberta-base-sentiment-latest, 132872180\n",
      "\n",
      "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, 25250863\n",
      "\n",
      "smilegate-ai/kor_unsmile, 10375883\n",
      "\n",
      "lxyuan/distilbert-base-multilingual-cased-sentiments-student, 7789676\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-irony, 7522276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_models\n",
    "\n",
    "def list_most_popular(task: str):\n",
    "    for rank, model in enumerate(list_models(filter=task, sort=\"downloads\", direction=-1)):\n",
    "        if rank == 5:\n",
    "            break\n",
    "        print(f\"{model.id}, {model.downloads}\\n\")\n",
    "        \n",
    "list_most_popular(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.7691405415534973}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "customer_email = \"\"\"\n",
    "I am writing to pour my heart out about the recent unfortunate experience\n",
    "I had with one of your coffee machines that arrived broken. I anxiously\n",
    "unwrapped the box containing my highly anticipated coffee machine.\n",
    "However, what I discovered within broke not only my spirit but also any\n",
    "semblance of confidence I had placed in your brand.\n",
    "Its once elegant exterior was marred by the scars of travel, resembling a\n",
    "war-torn soldier who had fought valiantly on the fields of some espresso\n",
    "battlefield. This heartbreaking display of negligence shattered my dreams\n",
    "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
    "and inconsolable\n",
    "\"\"\"\n",
    "\n",
    "sentiment_model = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    ")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-t5/t5-small, 3657071\n",
      "\n",
      "google-t5/t5-base, 2734080\n",
      "\n",
      "facebook/bart-large-cnn, 2351012\n",
      "\n",
      "philschmid/bart-large-cnn-samsum, 590044\n",
      "\n",
      "sshleifer/distilbart-cnn-12-6, 502373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_most_popular(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A customer\\'s coffee machine arrived broken. \"This heartbreaking display of negligence shattered my dreams,\" writes the customer. \"I was emotionally distraught and inconsolable,\" he adds. \"It was like a war-torn soldier who had fought valiantly on the fields of some espressobattlefield\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "summarizer = HuggingFaceHub(\n",
    "    repo_id=\"facebook/bart-large-cnn\",\n",
    "    model_kwargs={\"temperature\": 0, \"max_length\": 180}\n",
    ")\n",
    "\n",
    "def summarize(llm, text) -> str:\n",
    "    return llm(f\"Summarize this: {text}!\")\n",
    "    \n",
    "summarize(summarizer, customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven this text, decide what is the issue the customer is\n",
      "concerned about. Valid categories are these:\n",
      "* product issues\n",
      "* delivery problems\n",
      "* missing or late orders\n",
      "* wrong product\n",
      "* cancellation request\n",
      "* refund or exchange\n",
      "* bad support experience\n",
      "* no clear reason to be upset\n",
      "Text: \n",
      "I am writing to pour my heart out about the recent unfortunate experience\n",
      "I had with one of your coffee machines that arrived broken. I anxiously\n",
      "unwrapped the box containing my highly anticipated coffee machine.\n",
      "However, what I discovered within broke not only my spirit but also any\n",
      "semblance of confidence I had placed in your brand.\n",
      "Its once elegant exterior was marred by the scars of travel, resembling a\n",
      "war-torn soldier who had fought valiantly on the fields of some espresso\n",
      "battlefield. This heartbreaking display of negligence shattered my dreams\n",
      "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
      "and inconsolable\n",
      "\n",
      "Category:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " product issues\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import VertexAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Given this text, decide what is the issue the customer is\n",
    "concerned about. Valid categories are these:\n",
    "* product issues\n",
    "* delivery problems\n",
    "* missing or late orders\n",
    "* wrong product\n",
    "* cancellation request\n",
    "* refund or exchange\n",
    "* bad support experience\n",
    "* no clear reason to be upset\n",
    "Text: {email}\n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"email\"])\n",
    "llm = VertexAI()\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "print(llm_chain.run(customer_email))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fa8f4d2691e1735b84a26ae78635d39fd2d0e46f37776cabb5e361a9060a13d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
