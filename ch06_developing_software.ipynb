{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 6: Developing Software with Generative AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from config import set_environment\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing code with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StarCoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc993db350ed4283894d44faf57b0e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b929973aa6b74fd8bc87b358f053f9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/797M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a82a9720a64d3385d957f49f6a2db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/240 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fc97640d6846a39c266b4570a4474b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e22a9cd4c654c6990780f562072ce00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fab34faea7b4fdf938f73835f573035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8d61440df84852b7205b6801fd5fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b87b7f6ff14668bcde3b2f37c96dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "checkpoint = \"Salesforce/codegen-350M-mono\"\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "def calculate_primes(n):\n",
    "    \\\"\\\"\\\"Create a list of consecutive integers from 2 up to N.\n",
    "    For example:\n",
    "    >>> calculate_primes(20)\n",
    "    Output: [2, 3, 5, 7, 11, 13, 17, 19]\n",
    "\\\"\\\"\\\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def calculate_primes(n):\n",
      "    \"\"\"Create a list of consecutive integers from 2 up to N.\n",
      "    For example:\n",
      "    >>> calculate_primes(20)\n",
      "    Output: [2, 3, 5, 7, 11, 13, 17, 19]\n",
      "\"\"\"\n",
      "    p = 3\n",
      "    k = 1\n",
      "    p_k = []\n",
      "    while k < n:\n",
      "        if is_prime(p):\n",
      "            p_k.append(p)\n",
      "            k += 1\n",
      "        p += 1\n",
      "    return p_k\n",
      "\n",
      "\n",
      "def is_prime(n):\n",
      "    \"\"\"If n is a prime number, then return true. Otherwise return false.\n",
      "    >>> is_prime(34)\n",
      "    True\n",
      "    >>> is_prime(37)\n",
      "    False\n",
      "    \"\"\"\n",
      "    if n <= 1:\n",
      "        raise ValueError(\"n must be greater than 1\")\n",
      "    for i in range(2, round(n ** 0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "\n",
      "def count_conv(n):\n",
      "    \"\"\"Count all divisors of prime numbers up to number N.\n",
      "    >>> count_conv(20)\n",
      "    Output: 9\n",
      "    >>> count_conv(24)\n",
      "    Output: 11\n",
      "    \"\"\"\n",
      "    if is_prime(n):\n",
      "        return 1\n",
      "    k = 2\n",
      "    primes = []\n",
      "    for n in range(2, n + 1):\n",
      "        if is_prime(n):\n",
      "            primes.append(n)\n",
      "            k += 1\n",
      "    return k\n",
      "\n",
      "\n",
      "def primesup_to(n):\n",
      "    \"\"\"Create a list of all prime numbers up to the given number.\n",
      "    Useful so you can test for primesup_to(1000), not 1000 - 1000.\n",
      "    >>> primesup_to(10)\n",
      "    [2, 3, 5, 7, 11]\n",
      "    \"\"\"\n",
      "    if n <= 1:\n",
      "        raise ValueError(\"n must be greater than 1\")\n",
      "    result = [[] for _ in range(n + 1)]\n",
      "    for nn in range(2, n + 1):\n",
      "        for i in reversed(range(2, nn + 1)):\n",
      "            if nn % i == 0:\n",
      "                i2 = 2\n",
      "                while i2 < nn:\n",
      "                    if i2 % i == 0:\n",
      "                        i2 += 1\n",
      "                    else:\n",
      "                        break\n",
      "                if i2 == nn:\n",
      "                    result[nn].append(i)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "completion = pipe(text)\n",
    "print(completion[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating software development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what a prime number is\n",
      "Action: print(...)\n",
      "Action Input: 20\u001b[0m\n",
      "Observation: print(...) is not a valid tool, try one of [Python_REPL].\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m A prime number is a number that is only divisible by 1 and itself\n",
      "Action: Python_REPL\n",
      "Action Input: 2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 2 is a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 3\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 3 is a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 4\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 4 is not a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 5 is a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 6\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 6 is not a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 7\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 7 is a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 8\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 8 is not a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 9\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 9 is not a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 10\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 10 is not a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 11\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 11 is a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 12\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 12 is not a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 13\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 13 is a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 14\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 14 is not a prime number\n",
      "Action: Python_REPL\n",
      "Action Input: 15\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What are the prime numbers until 20?', 'output': 'Agent stopped due to iteration limit or time limit.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "tools = load_tools([\"python_repl\"])\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "result = agent(\"What are the prime numbers until 20?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain_experimental.plan_and_execute import load_chat_planner, load_agent_executor, PlanAndExecute\n",
    "\n",
    "llm = OpenAI()\n",
    "planner = load_chat_planner(llm)\n",
    "executor = load_agent_executor(\n",
    "    llm,\n",
    "    tools,\n",
    "    verbose=True,\n",
    ")\n",
    "agent_executor = PlanAndExecute(\n",
    "    planner=planner,\n",
    "    executor=executor,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"Check your output and make sure it conforms!\",\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "agent_executor.run(\"Write a tetris game in python!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain, OpenAI\n",
    "\n",
    "DEV_PROMPT = (\n",
    "    \"You are a software engineer who writes Python code given tasks or objectives. \"\n",
    "    \"Come up with a python code for this task: {task}\"\n",
    "    \"Please use PEP8 syntax and comments!\"\n",
    ")\n",
    "software_prompt = PromptTemplate.from_template(DEV_PROMPT)\n",
    "software_llm = LLMChain(\n",
    "    llm=OpenAI(\n",
    "        temperature=0,\n",
    "        max_tokens=1000\n",
    "    ),\n",
    "    prompt=software_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonDeveloper():\n",
    "    \"\"\"Execution environment for Python code.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_chain: Chain\n",
    "    ):\n",
    "        self.llm_chain = llm_chain\n",
    "        \n",
    "    def write_code(self, task: str) -> str:\n",
    "        return self.llm_chain.run(task)\n",
    "        \n",
    "    def run(\n",
    "        self,\n",
    "        task: str,\n",
    "    ) -> str:\n",
    "        \"\"\"Generate and Execute Python code.\"\"\"\n",
    "        code = self.write_code(task)\n",
    "        try:\n",
    "            return self.execute_code(code, \"main.py\")\n",
    "        except Exception as ex:\n",
    "            return str(ex)\n",
    "            \n",
    "    def execute_code(self, code: str, filename: str) -> str:\n",
    "        \"\"\"Execute a python code.\"\"\"\n",
    "        try:\n",
    "            with set_directory(Path(self.path)):\n",
    "                ns = dict(__file__=filename, __name__=\"__main__\")\n",
    "                function = compile(code, \"<>\", \"exec\")\n",
    "                with redirect_stdout(io.StringIO()) as f:\n",
    "                    exec(function, ns)\n",
    "                    return f.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from software_development.python_developer import PythonDeveloper, PythonExecutorInput\n",
    "\n",
    "software_dev = PythonDeveloper(llm_chain=software_llm)\n",
    "code_tool = Tool.from_function(\n",
    "    func=software_dev.run,\n",
    "    name=\"PythonREPL\",\n",
    "    description=(\n",
    "        \"You are a software engineer who writes Python code given a function description or task.\"\n",
    "    ),\n",
    "    args_schema=PythonExecutorInput\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fa8f4d2691e1735b84a26ae78635d39fd2d0e46f37776cabb5e361a9060a13d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
